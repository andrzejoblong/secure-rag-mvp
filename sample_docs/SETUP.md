# Setup Sample Documents

Ten przewodnik opisuje jak zaÅ‚adowaÄ‡ przykÅ‚adowe dokumenty do systemu RAG przed uruchomieniem ewaluacji.

## ğŸ“ Sample Documents

System zawiera 3 przykÅ‚adowe dokumenty testowe:

1. **SmartHome_Manual.txt** - Instrukcja obsÅ‚ugi systemu Smart Home Pro v2.1
   - 10 sekcji technicznych
   - Wymagania, instalacja, konfiguracja, rozwiÄ…zywanie problemÃ³w
   - ~7000 sÅ‚Ã³w

2. **Invoice_FV_2025_0847.txt** - Faktura VAT
   - 10 pozycji (laptopy, monitory, akcesoria IT)
   - SzczegÃ³Å‚y finansowe, terminy pÅ‚atnoÅ›ci
   - ~1500 sÅ‚Ã³w

3. **Contract_SVC_0089.txt** - Umowa zlecenia na projekt IT
   - 10 paragrafÃ³w: zakres, terminy, wynagrodzenie, gwarancja
   - Kamienie milowe, kary umowne, prawa autorskie
   - ~3500 sÅ‚Ã³w

## ğŸš€ Jak zaÅ‚adowaÄ‡ dokumenty

### Opcja A: Przez API (zalecane)

```bash
# Upewnij siÄ™ Å¼e API dziaÅ‚a
curl http://localhost:8000/health

# ZaÅ‚aduj wszystkie 3 dokumenty
for file in sample_docs/*.txt; do
  echo "Uploading $file..."
  curl -X POST http://localhost:8000/documents \
    -F "file=@$file"
  echo ""
  sleep 5  # Poczekaj na przetworzenie
done
```

### Opcja B: Przez Swagger UI

1. OtwÃ³rz http://localhost:8000/docs
2. Endpoint `POST /documents`
3. Kliknij "Try it out"
4. Upload kaÅ¼dego pliku z `sample_docs/`
5. Poczekaj aÅ¼ processing siÄ™ zakoÅ„czy (check logs)

### Opcja C: Skrypt Python

```python
import requests
import time
from pathlib import Path

API_URL = "http://localhost:8000"
DOCS_DIR = Path("sample_docs")

for doc_file in DOCS_DIR.glob("*.txt"):
    print(f"Uploading {doc_file.name}...")
    
    with open(doc_file, 'rb') as f:
        response = requests.post(
            f"{API_URL}/documents",
            files={"file": (doc_file.name, f, "text/plain")}
        )
    
    if response.status_code == 200:
        doc_id = response.json()["id"]
        print(f"  âœ“ Uploaded: {doc_id}")
    else:
        print(f"  âœ— Error: {response.text}")
    
    time.sleep(5)  # Wait for processing

print("\nâœ“ All documents uploaded!")
```

## âœ… Weryfikacja

SprawdÅº czy dokumenty zostaÅ‚y przetworzone:

```bash
# Lista dokumentÃ³w
curl http://localhost:8000/documents

# SprawdÅº szczegÃ³Å‚y kaÅ¼dego
curl http://localhost:8000/documents/{document_id}
```

KaÅ¼dy dokument powinien mieÄ‡:
- `chunks` > 0 (liczba chunkÃ³w)
- `embeddings` > 0 (wygenerowane embeddingi)

PrzykÅ‚adowe liczby chunkÃ³w (z chunk_size=1000, overlap=150):
- SmartHome_Manual.txt: ~45-55 chunkÃ³w
- Invoice_FV_2025_0847.txt: ~8-12 chunkÃ³w  
- Contract_SVC_0089.txt: ~20-25 chunkÃ³w

## ğŸ§ª Test pojedynczego zapytania

Przetestuj czy RAG dziaÅ‚a:

```bash
curl -X POST http://localhost:8000/answer \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Jaki jest numer faktury?",
    "top_k": 5
  }'
```

Powinno zwrÃ³ciÄ‡:
```json
{
  "answer": "Numer faktury to FV/2025/01/0847.",
  "citations": [
    {
      "document_id": "...",
      "document_title": "Invoice_FV_2025_0847.txt",
      "page_number": 1,
      "chunk_id": 3,
      "quote": "FAKTURA VAT / INVOICE Nr / No: FV/2025/01/0847"
    }
  ],
  "has_sufficient_context": true
}
```

## ğŸ“Š Uruchomienie peÅ‚nej ewaluacji

Po zaÅ‚adowaniu wszystkich dokumentÃ³w:

```bash
# Uruchom 30 pytaÅ„
python eval/run_evaluation.py

# SprawdÅº wyniki
python eval/analyze_results.py
```

## ğŸ”§ Troubleshooting

### Dokumenty siÄ™ nie przetwarzajÄ…
- SprawdÅº logi API (`docker-compose logs app`)
- SprawdÅº czy sentence-transformers zostaÅ‚ pobrany
- SprawdÅº poÅ‚Ä…czenie z bazÄ… danych

### Brak embeddingÃ³w
- SprawdÅº zmiennÄ… `EMBEDDING_TYPE` w logach API
- JeÅ›li uÅ¼ywasz local - zweryfikuj instalacjÄ™ sentence-transformers
- JeÅ›li OpenAI - sprawdÅº `OPENAI_API_KEY`

### Query nie zwraca wynikÃ³w
- SprawdÅº czy embeddingi zostaÅ‚y wygenerowane: `GET /documents/{id}`
- SprawdÅº czy pgvector dziaÅ‚a: `docker-compose ps`
- ZwiÄ™ksz `top_k` do 10-20

## ğŸ“ Dodawanie wÅ‚asnych dokumentÃ³w

MoÅ¼esz dodaÄ‡ wÅ‚asne pliki .txt do `sample_docs/`:

1. StwÃ³rz plik tekstowy z treÅ›ciÄ…
2. Upload przez API
3. Dodaj pytania do `eval/questions.jsonl`:
   ```json
   {"id":"q31","question":"...","expected":"...","must_cite":true,"category":"answerable","document":"your_doc"}
   ```
4. Uruchom ponownie ewaluacjÄ™

## ğŸ¯ Co dalej?

Po zaÅ‚adowaniu sample docs i uruchomieniu ewaluacji:

1. **Manualne scorowanie** - Edytuj `eval/evaluation_results.json`
2. **Analiza wynikÃ³w** - `python eval/analyze_results.py`
3. **Iteracja** - Dostosuj chunking, prompts, lub top_k
4. **Re-evaluate** - Uruchom ponownie i porÃ³wnaj wyniki
